

##### ZZZzz  18:03:25
> It is humbling to read Alan Turing’s papers. He thought of it all.

##### MyLips  18:05:10
> 图灵是个数学家 在看他看来一切都是图灵机 都是非常高的抽象了

##### ZZZzz  18:05:52
> 数学只是他的一个方面

##### ZZZzz  18:06:27
> 买了一套他的论文集，好好研究一下

##### MyLips  18:07:05
> 自己比较忙 没时间研究这些 所以说好久都没开悟了

##### MyLips  18:07:21
> 你有研究过了没

##### ZZZzz  18:11:30
> 【链接】被遗忘的图灵：人工智能之父
https://m.sohu.com/a/237401249_313170/?pvid=000115_3w_a

##### 赤臂生  18:28:21
> @江苏-午夜 我以为他说的是prolog话说protocol也不对啊;他这拼的有点蒙;

##### 赤臂生  18:32:58
> @ZZZzz

##### 压力山大  19:01:31
> 话说人 为什么喜欢大眼

##### 夜行CT  19:03:50
> 那得知道人的审美观是怎么形成的...

##### 压力山大  19:04:11
> 说的有理

##### 压力山大  19:04:20
> 怎么形成的呢

##### 江苏-午夜  19:04:45
> 有趣

##### 江苏-午夜  19:04:59
> 我提一个猜想：更容易从中获得信息

##### 夜行CT  19:05:09
> 是不是从婴儿看到妈妈开始形成的

##### 江苏-午夜  19:06:14
> 按我的猜想，不是，而且盲人不会有这一倾向

##### 压力山大  19:06:59
> 盲人的审美是什么

##### 夜行CT  19:07:16
> 盲人不会有视觉上的审美吧(或许能从-触摸建立空间形状的审美)

##### 压力山大  19:07:55
> 呵呵

##### 压力山大  19:08:21
> 还是撤回吧

##### 压力山大  19:08:28
> 影响不好

##### 赤臂生  19:08:36
> 数据原本没意义,只是有了mindValue才有了意义;所以审美只是数据与mv之间,有了数据关联;

##### 赤臂生  19:08:57
> 我的意思是,各种各样的感觉,都是基于那几种最简单的情感;

##### 江苏-午夜  19:09:31
> 研究感觉，在确认是否存在时，要自己体会

##### 江苏-午夜  19:09:50
> 而研究它的性质时，要当成别人的感觉

##### 赤臂生  19:10:26
> 鸠摩智觉得,疼就是乔峰拍了一耳光;而段誉却觉得,是得到王姑娘是妹妹后,心最疼;

##### 压力山大  19:12:28
> 你这个道理是对的，但是例子不太恰当。
但里边我才发现有两种什么方式

##### 压力山大  19:12:39
> 一种是原始的原生的审美

##### 压力山大  19:12:44
> 一种是后期形成的

##### 压力山大  19:12:50
> 后期的就想你说的

##### 压力山大  19:12:59
> 每个人都不同

##### 压力山大  19:13:09
> 先天的则每个人都相同

##### 压力山大  19:14:27
> 打错了 两种审美方式

##### 赤臂生  19:15:13
> 恩,对,我同意你说的;

##### 夜行CT  19:15:43
> 审美这种高级本能真的很难理解

##### 压力山大  19:16:30
> 你们先聊着，我去学习一下smg

##### 夜行CT  19:16:31
> 比如你们说非洲男人喜欢非洲女人还是欧洲白人女人？

##### error:0  19:21:32
> Smg有视频吗

##### error:0  19:22:02
> github我看不懂

##### 江苏-午夜  19:22:05
> 环境足以改变这个倾向了

##### 赤臂生  19:25:44
> @压力山大 太给脸了,谢谢;

##### 赤臂生  19:25:57
> @error:0 有三个视频吧;

##### 赤臂生  19:26:11
> 今天刚给公司技术部门作了smg的技术分享;

##### 赤臂生  19:27:26
> 结果是一样的,一脸蒙bi;可见我的表达能力实在是很差,后天去见由小川,如果结果还是一样,我就老实先把smg做落地再说吧,目前也完成了70%左右了,估计今年底之前,能放个demo出来,

##### 赤臂生  19:27:48
> 不过估计,到时候,就算看到了那个弱弱的demo,也是少不了不理解,少不了质疑;

##### 夜行CT  19:32:42
> 估计你能在半小时给群里再说明白两人就好给外面的人说了

##### 江苏-午夜  19:33:09
> 我有空用py翻译试试

##### 赤臂生  19:36:40
> @夜行CT 实话说,我那套东西,真不是几个小时能说明白的;

##### 赤臂生  19:36:55
> 不说AI系统了,就单拿面向对象这种东西,初学者,也是要一段时间慢慢理解的;

##### 赤臂生  19:37:11
> 并且oop这种东西,还是和人类很多思考方式一样的;

##### 赤臂生  19:37:45
> AI系统更抽象更核心些,并且很多东西非常隐性,还有些是呈现在整体性之上的,

##### 夜行CT  19:37:48
> 不说技术的东西  只说架子

##### 夜行CT  19:38:19
> 不要带指针等实现方面  只说基础原理

##### 赤臂生  19:38:20
> 就拿smg的意识来说,估计现在除了我自己,能真正理解的也没几个,(并且我自己还可能是错的,别人不理解也正常)

##### 人工智能深度学习  19:38:38
> 恩,正常.

##### 夜行CT  19:38:47
> 你例子里面充一下电那个例子可以再细讲讲

##### 赤臂生  19:38:56
> 那个啊,那个好说;

##### 赤臂生  19:39:25
> 我想再过两三个月,我能直接让我的手机,真正用字符串的方式来和我交流充电需求;

##### 赤臂生  19:39:36
> 到时候,会更方便 说些;

##### 赤臂生  19:39:45
> 现在我都没完全跑通;

##### 人工智能深度学习  19:39:46
>

##### 赤臂生  19:40:10
> 可能会比较弱,就像小婴儿,刚学会说话的时候,只会说"吃"或者"奶"一样;

##### 人工智能深度学习  19:40:15
> 那你是怎么给充电用的数据呢?

##### 赤臂生  19:40:25
> 也有可能更早期,就像只会用表情符号等表示一样;

##### 赤臂生  19:40:31
> 那个简单;

##### 赤臂生  19:40:43
> 充电数据,直接写成了mindValue的一个类型;

##### 夜行CT  19:40:53
> 比如  告诉smg程序充一下 最后谁靠什么执行了这个动作/行为

##### 人工智能深度学习  19:41:10
> 我明白了.

##### 人工智能深度学习  19:41:15
> 就是,MindValue.

##### 人工智能深度学习  19:41:28
> 这个数据,你是人工给进去的还是怎么获得的?

##### 赤臂生  19:43:03
> 手机设备,在电量变化时,有广播;

##### 赤臂生  19:43:06
> 这个很容易;

##### 赤臂生  19:43:25
> 这种状态变化,很方便传给smg;

##### 赤臂生  19:44:01
> @夜行CT smg所经历的信息输出,最初时,对他而言,没有任何 意义;

##### 赤臂生  19:44:16
> 他只是对信息类比找规律,并归纳抽象网络;

##### 赤臂生  19:44:45
> 说白了,你如果有小和婴儿说eat;他就觉得eat是吃;如果说"吃",他就觉得"吃"是"吃"

##### 赤臂生  19:46:15
> smg概述: https://www.bilibili.com/video/av23032150
>
##### 赤臂生  19:47:18
> smg理论: https://v.youku.com/v_show/id_XMzY1NTAyMzc2OA==.html?spm=a2hww.11359951.uerCenter.5!3~5~5!2~5~DL~DD!2~A

##### 赤臂生  19:47:29
> smg实践: https://v.youku.com/v_show/id_XMzY1NTAyNTg2MA==.html?spm=a2h0j.11185381.listitem_page1.5~A

##### 赤臂生  19:48:12
> smgPPT: https://github.com/jiaxiaogang/SMG_NOTE/blob/master/Other/9_%E5%85%AC%E5%8F%B8%E5%86%85AI%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB20180628.pptx

##### 人工智能深度学习  19:49:51
> 你的PPT好象不见了.

##### 压力山大  19:51:20
> " 赤臂生 19:25:44
> @压力山大 太给脸了,谢谢; "
严重了，大家都是好朋友，你很强 很随和。

不知道你找教授的干什么，反正我认为你这个行。

##### 江苏-午夜  19:52:02
> " 人工智能深度学习 19:49:51
> 你的PPT好象不见了. "
不能在线查看，可以下载

##### error:0  19:52:14
> 关键我就是不清楚这些方法描述

##### 赤臂生  19:52:16
>

##### 赤臂生  19:52:29
> @人工智能深度学习 这个ppt应该要下载下来,不能在线看;

##### 人工智能深度学习  19:52:40
> 恩.

##### 赤臂生  19:52:48
> 我发个在群文件吧;不过那个ppt,没录视频,估计一个ppt,也就看个画;

##### error:0  19:53:00
> 什么时候类比了  二分法查找了  这些所以我要弄清楚还要看你那个视频

##### 人工智能深度学习  19:53:13
> 然后我觉得对于AI,大家可以参考下IBM

##### 压力山大  19:54:01
> 有空我给大家翻译成白话

##### 人工智能深度学习  19:54:13
> IBM,我感觉就是领导不太懂技术, 方向走错了.

##### 赤臂生  19:54:24
> @压力山大 也不算我找他,他在微信主动联系我过去聊聊,我总不能说不去,嘻嘻,何况,兴许能给我些思路呢;多交流,总是讨便宜的事儿;

##### 赤臂生  19:54:28
>

##### 人工智能深度学习  19:54:48
> 恩,必须的,你最好和他照几张合影.

##### 人工智能深度学习  19:54:57
> 留个证据.

##### 赤臂生  19:55:12
> @error:0 类比,就是两个值对比,比大小,哪个大,是否一样大;

##### 赤臂生  19:55:30
> 二分法,那个更简单,就是能快速检索有序序列的;

##### 赤臂生  19:55:45
> 其实二分法,不是最好的方式,只是在smg中,够用了,也足够简单;

##### 赤臂生  19:56:05
> @人工智能深度学习 啥证据;

##### 压力山大  19:56:18
> " 赤臂生 19:54:24
> @压力山大 也不算我找他,他在微信主动联系我过去聊聊,我总不能说不去,嘻嘻,何况,兴许能给我些思路呢;多交流,总是讨便宜的事儿; "
你这个东西，做的很好，他看你是个人才。想拉拢你

##### 赤臂生  19:56:35
> @人工智能深度学习 ibm很强,这点@超联人工智能 应该比我了解更多;我也了解过ibm的作法,只是不算深入;

##### 赤臂生  19:57:27
> @压力山大 说实话,我都不认为有人能真正看懂smg,就是咱几个,也是长期交流,才算是描述明白了些,就我那些个笔记 和代码,乱的一pi,能看懂才见 鬼了;

##### 压力山大  19:57:31
> 欧洲人做不出AGI，因为他们的思维是还原思维。而系统的整体大于组合

##### 压力山大  19:57:42
> 但不排除他们会明白

##### 超联人工智能  19:57:43
> 我？我不太了解IBM啊

##### 赤臂生  19:58:13
> @超联人工智能 clips,专家系统,ibm当时好像作这些挺久的;

##### 超联人工智能  19:58:34
> 哦，专家系统接触贵一点

##### 超联人工智能  19:58:37
> 接触过

##### 赤臂生  19:58:37
> [文件]

##### 压力山大  19:58:38
> 看懂后，感觉你的思维，很牛

##### 压力山大  19:58:52
> 特别是图形思维 你很擅长

##### error:0  19:59:03
> Ibm的AI叫什么

##### 压力山大  19:59:17
> 深蓝

##### 人工智能深度学习  19:59:21
> @赤臂生 你们见面的证据啊.

##### 赤臂生  19:59:52
> @人工智能深度学习 到时候拍个照,估计我这一脸胡渣子,比他还呈老;嘻嘻...

##### 人工智能深度学习  19:59:57
> 以后咱们这个AGI要搞好了.也少不得让专家教授们帮你站站台什么的.

##### 赤臂生  20:00:04
>

##### 赤臂生  20:00:27
> 真搞好了,对人类的进程是一大步,并且造福更多人;

##### 人工智能深度学习  20:00:33
> 是的.

##### 赤臂生  20:00:36
> 站不站台,都已经不重要了,无所谓;

##### 人工智能深度学习  20:01:07
> 然后IBM,我认为跑偏就是当时你说的那个思路.

##### 赤臂生  20:01:28
> 你看下,我的ppt,里面有个妥协落地;

##### 人工智能深度学习  20:01:34
> 就是,再强的算力和再多的数据,硬堆也堆不出来足够的智商.

##### 赤臂生  20:01:43
> 里面列出来那几个,都有致命伤;

##### 赤臂生  20:01:52
> 恩;对;

##### 人工智能深度学习  20:02:09
> IBM的AI走的就是这条道,而且用在医疗上,那当然败的可能性高达99%了.

##### 人工智能深度学习  20:02:17
> 象Google走的方向就对路.

##### 人工智能深度学习  20:02:35
> 不断的让系统更优化更聪明更灵活.

##### 人工智能深度学习  20:02:57
> 用在玩游戏,下棋这些"无关紧要"的地方.

##### 人工智能深度学习  20:03:38
> 试想下,如果AI连游戏都没玩好,直接上台做手术这行不行.

##### 赤臂生  20:03:51
> @人工智能深度学习 对,你说到点子上了;

##### 人工智能深度学习  20:03:52
> IBM这一战估计元气大伤.

##### 人工智能深度学习  20:03:57
>

##### 人工智能深度学习  20:04:21
> 太急于变现赚钱了.

##### 压力山大  20:04:35
> 这些都是小钱

##### 压力山大  20:04:56
> 银河系中 有多少金矿 钻石 太阳能

##### 人工智能深度学习  20:05:10
> 但是IBM的失败,对让整个AI研发圈走向正轨.就是更多人会转向研发更聪明更灵活的AI

##### 压力山大  20:05:38
> 对

##### 人工智能深度学习  20:05:51
> 而不是堆砌硬件和数据.这样的话.AGI这个正确的方向就真正的指出来了.

##### 压力山大  20:06:02
> 腾讯已经开始

##### 人工智能深度学习  20:06:35
> 是的,通用AI的以前我总结过的两大技术点,1.记忆,2.价值网络.

##### 人工智能深度学习  20:06:51
> 这两个技术点,很可能会在短时间内被解.

##### 赤臂生  20:08:27
> @人工智能深度学习 企业偏应用，ibm前面也有过很多其它人的做法，共同导致肯定有人这么尝试。

##### 人工智能深度学习  20:08:45
> 是的.

##### 人工智能深度学习  20:08:52
> 这就是探路者.

##### 人工智能深度学习  20:09:20
> 就象3体里面描述的.

##### 人工智能深度学习  20:09:36
> 研发燃料引擎的那派倒下后.

##### 人工智能深度学习  20:09:46
> 研发曲速引擎的那派就起来了.

##### 人工智能深度学习  20:09:51
>

##### 赤臂生  20:09:55
> 只是正如@压力山大 所说:欧美就那样。整个做系统的方式，他们尝够了鲜，转不来身

##### 赤臂生  20:10:37
> @人工智能深度学习

##### 人工智能深度学习  20:11:29
> 我从直觉上看,AI记忆问题可能会更容易解.可能2,3年内就会有不错的方法了.

##### MyLips  20:11:31
> 欧美的学术和科研牛逼着  人工智能远远超国内 只是我们不知道

##### 赤臂生  20:11:33
> 所以我一直说，前人的努力非常有价值，无论是成果还是教训。我认可每个前辈曾经的努力。

##### 人工智能深度学习  20:11:42
> 价值网络的话,你的MindValue这个可能是对的.

##### 赤臂生  20:11:59
> @人工智能深度学习 网络可以解记忆问题

##### 人工智能深度学习  20:12:16
> 但要做到象人类一样聪明,可能还缺一些我们不知道的细节.

##### 赤臂生  20:12:27
> 你可以看看cmv基本模型和索引序列，引用序列，时序列

##### 人工智能深度学习  20:13:16
> 恩,我说下关于技术的技术上我想到的一个思路.因为我对AI技术还不太懂,我只能说编程上的.

##### 人工智能深度学习  20:13:30
> 就是我们使用神经网络的时候.

##### 赤臂生  20:13:32
> 数据与网络的整合是非常好的一种做法

##### 人工智能深度学习  20:13:41
> 每个网络节点是有一个函数的.

##### 人工智能深度学习  20:13:45
> 是的.

##### 人工智能深度学习  20:13:56
> 怎么整合数据和网络呢?或者说数据和函数.

##### 人工智能深度学习  20:14:15
> 函数式编程里,可以使用函数来表达函数或一个值.

##### 赤臂生  20:14:17
> 这个可以，我已经实现了。

##### 人工智能深度学习  20:14:26
> 恩.那你可能就是这个思路.

##### 赤臂生  20:15:03
> 思维源于网络，网络源于思维

##### 人工智能深度学习  20:15:07
> 就是把值也用函数式来表达,来返回一个可计算的值.

##### 赤臂生  20:15:11
> 数据即索引

##### 人工智能深度学习  20:15:24
> 恩.

##### 人工智能深度学习  20:15:42
> 那你是怎么存储它呢?

##### 赤臂生  20:15:48
> 微信息与宏信息以相对的方式螺旋式构建

##### 赤臂生  20:16:09
> 存sql,kv,随便，都可以

##### 赤臂生  20:16:13
> 这个是分层的

##### 赤臂生  20:16:18
> 随便换

##### 赤臂生  20:16:26
> 也可以存网络

##### 人工智能深度学习  20:17:02
> 恩,那么获取的时候全部是通过调用函数获取?

##### 人工智能深度学习  20:18:22
> 我想想啊,如果通过函数式的方式,把MindValue,变成一个函数的MindValue();

##### 赤臂生  20:18:22
> 思维从网络取

##### 人工智能深度学习  20:18:33
> 这样的话,这个MindValue就是抽象的.

##### 赤臂生  20:18:38
> 我一下抛太多名词概念了

##### 赤臂生  20:19:09
> 不过不抛不行，因为这些共同说明白，才能讲明白你的问题。

##### 人工智能深度学习  20:19:13
> 恩,你的MindValue是一个抽象的值,是吧?

##### 赤臂生  20:19:46
> @人工智能深度学习 恩，对

##### 人工智能深度学习  20:19:57
> 恩,那我明白了,那就是和我想的一样了.

##### 人工智能深度学习  20:20:22
> 只有这样,所获取的值,就可以是全网络的.

##### 赤臂生  20:20:32
> mindValue因为数据关联，而意义被升华了

##### 人工智能深度学习  20:20:41
>

##### 人工智能深度学习  20:20:49
> 对,正是这样.

##### 人工智能深度学习  20:21:20
> 然后这个MindValue加上存储结构,那么连带的记忆问题也有解了.

##### 赤臂生  20:21:24
> @人工智能深度学习 有生于无，而有一则有万

##### 赤臂生  20:21:32
> @人工智能深度学习 对

##### 人工智能深度学习  20:21:42
>

##### 赤臂生  20:21:47
> 所以我说cmv基础模型是网络的根

##### 赤臂生  20:22:09
> 网络是从这上面成长起来的。

##### 人工智能深度学习  20:22:13
> cmv基础模型?

##### 赤臂生  20:22:22
> 基本

##### 赤臂生  20:22:28
> 我打错了

##### 赤臂生  20:23:08
> 数据的静因为cmv基本模型而有了时序的概念

##### 赤臂生  20:23:12
> 即因果

##### 赤臂生  20:23:15
> 前后

##### 人工智能深度学习  20:23:30
> CMV是什么?

##### 赤臂生  20:23:32
> 导致cmv变化的信息

##### 人工智能深度学习  20:23:35
> 是你搞的概念?

##### 赤臂生  20:23:41
> changeMindValue

##### 赤臂生  20:23:47
> 就是这值变了

##### 赤臂生  20:23:55
> 但有原因导致了变化

##### 赤臂生  20:27:02
> 其实我很难描述明白smg有个主要原因，就是smg里有很多很多细节，被集成到非常短的代码中，整合到理论中，而这些细节都是有非常深的原因的，我却一语带过，在视频分享时，往往很多这些都几秒钟带过。

##### 赤臂生  20:27:11
> 当然，主要是时间原因

##### 赤臂生  20:28:48
> [动作消息]考神附体

##### 赤臂生  20:28:55
> [动作消息]感到鸭力

##### 人工智能深度学习  20:28:59
> 恩,如果我没理解错,你想的和我想的应该是类似的东西.

##### 人工智能深度学习  20:29:08
> 就是MindValue

##### 江苏-午夜  20:29:19
> 反而长代码不一定重要。

##### 赤臂生  20:29:19
> 恩，对。

##### 人工智能深度学习  20:29:22
> 这是一个抽象的值.可以是任何东西.

##### 杨柳岸  20:29:42
> 如何构建因果啊

##### 赤臂生  20:29:44
> 我过去17天，思考了17天，只写了一行代码。

##### 人工智能深度学习  20:29:47
> 可以是一个固定值,比如Bool, Number或者字符串,或者一个调用其它的函数.

##### 赤臂生  20:29:54
> 然后写完后，问题解决了。

##### 人工智能深度学习  20:30:01
> 然后就是ChangeMindValue

##### 杨柳岸  20:30:06
> 因果是一个复杂的关联过程吧

##### 人工智能深度学习  20:30:20
> @杨柳岸 就是高阶函数.

##### 人工智能深度学习  20:30:29
> 我们以前讨论过的那个东西.

##### 赤臂生  20:30:31
> @杨柳岸 想复杂了，你想一个最最简单的。

##### 杨柳岸  20:31:08
> 比如，德国爆冷世界杯，结果出来了，能直接得到原因吗

##### 人工智能深度学习  20:31:31
> 因果我认为就是函数的不可变数据.

##### 人工智能深度学习  20:31:36
> 函数式.

##### 人工智能深度学习  20:32:03
> 最终你是通过神经网络计算出来的值吧.

##### 人工智能深度学习  20:32:44
> 我的理解是,比如我们最初的数据是,吃, 食物.

##### 人工智能深度学习  20:32:53
> 吃和食物建立关联.

##### 江苏-午夜  20:33:06
> " 杨柳岸 20:29:42
> 如何构建因果啊 "
我从另一个角度问：为什么需要因果？》

##### 人工智能深度学习  20:33:16
> 然后是,食物,非食物.

##### 人工智能深度学习  20:33:27
> 这样,物品和食物,建立关联.

##### 江苏-午夜  20:33:29
> 人的智能不需要因果就可以，人只要猜猜

##### 人工智能深度学习  20:33:43
> 这样,最后这个物品,经过三层计算后,到达吃这一个输出层.

##### 人工智能深度学习  20:33:55
> 猜测就是概率.

##### 人工智能深度学习  20:33:56
> 一样的.

##### 人工智能深度学习  20:34:02
> 也能用数据和计算来表达.

##### 人工智能深度学习  20:34:24
> 刚才我描述了一个三层,这就是道生一,一生二,二生三.

##### 赤臂生  20:34:28
> @江苏-午夜 确切说，不是因果，是时间

##### 人工智能深度学习  20:34:32
> 这个过程进行下去,就生万物.

##### 人工智能深度学习  20:34:47
> 恩,对.

##### 人工智能深度学习  20:35:10
> 时间的变化,导致了这个过程越来越复杂.但最终流向是精确的.

##### 人工智能深度学习  20:35:20
> 这样就形成了AI的生长.

##### 人工智能深度学习  20:35:35
> @赤臂生 是我说的这个概念么?

##### 赤臂生  20:36:14
> @人工智能深度学习 对

##### 人工智能深度学习  20:36:27
>

##### 人工智能深度学习  20:36:42
> 那么就就是这个概念了.

##### 人工智能深度学习  20:36:53
> 我的思考和理解没有跑偏.

##### 赤臂生  20:36:58
> 道生一，三生万物，这句是smg的核心理论之一

##### 人工智能深度学习  20:37:47
> 牛,这样的话,你要能实现具体代码,那么这个AI在最初是能成长的.

##### 人工智能深度学习  20:38:31
> 因为我们还无法估算人类智能到底是什么程度,所以暂时无法检验这个生长的AI在条件足够下,是弱于人还是强于人.

##### 人工智能深度学习  20:38:56
> 但成长性和通用性,理论上是能保证的.

##### 杨柳岸  20:39:14
> 就是说，最开始只有一条特别简单得规则

##### 人工智能深度学习  20:39:23
> 是的.

##### 赤臂生  20:39:24
> @人工智能深度学习 如果只能佩服一个人，我首选老子。在读道德经前，我只信自己，读之后，我有太多太多太多不如老子思想的地方了。

##### 杨柳岸  20:39:27
> 然后在这个最简单的规则上面继续

##### 人工智能深度学习  20:39:40
> 是的.

##### 杨柳岸  20:39:48
> 所以，这个最简单的规则是什么 ？

##### 江苏-午夜  20:39:49
> 这值得研究，但是很难说和智能有必然关联

##### 人工智能深度学习  20:40:02
> 然后不断的迭代后就组成神经网络,最终是神经网络.

##### 赤臂生  20:40:04
> @杨柳岸 最简规则，也是smg的核心理论之一

##### 人工智能深度学习  20:40:56
> @赤臂生 要不牛为什么人家几千年前就敢自称老子呢.

##### 杨柳岸  20:40:59
> 应该是最简规则集合吧，因为这世界，根本没办法用一条规则来解释一切。

##### 江苏-午夜  20:41:09
> 如果是物理规则层面的

##### 赤臂生  20:41:10
> @江苏-午夜 和通用性关联，与智能应该无直接关联

##### 江苏-午夜  20:41:19
> 那么这属于“混沌规则”

##### 江苏-午夜  20:41:36
> 即使知道，也难以向后推导

##### 人工智能深度学习  20:41:37
> @江苏-午夜 主要是因为通用.

##### 人工智能深度学习  20:41:50
> 因为通用,加上神经网络的加持.

##### 人工智能深度学习  20:41:58
> 那么理论上也就形成了通用AI

##### 赤臂生  20:42:07
> 我去年初开始时就有了mindValue的相法，但直到10月份，又花了两个月思考最简规则

##### 杨柳岸  20:42:10
> 比如，计算机这种东西，其实就只有一个规则。

##### 杨柳岸  20:42:15
> 零和一

##### 江苏-午夜  20:42:25
> 规则，是说宇宙的规则，还是智能体的运行规则？这是两个话题

##### 赤臂生  20:42:39
> @杨柳岸 一条规则是不行，但有网络

##### 杨柳岸  20:42:55
> 最简规则啊，肯定是最简单的，就像 0 和 1 一样

##### 江苏-午夜  20:43:06
> " 杨柳岸 20:42:15
> 零和一 "
还要有几条演化规则

##### 杨柳岸  20:43:19
> 0 和 1，组成与门，非门，异或门，然后才有接下来的计算机。

##### 杨柳岸  20:43:35
> @江苏-午夜 嗯，布尔代数。

##### 杨柳岸  20:44:02
> 感觉有点类似西部世界得『基石』

##### 江苏-午夜  20:44:06
> 这些规则不能自己组装，要人为组合

##### 杨柳岸  20:45:02
> 要是认为组装，就是计算机这种东西啊

##### 杨柳岸  20:45:14
> 结果还是得有人控制。

##### 杨柳岸  20:45:23
> 人为，打错了。

##### 江苏-午夜  20:45:35
> 程序得编

##### 赤臂生  20:45:51
> @杨柳岸 活源于死

##### 杨柳岸  20:46:13
> 是啊，感觉关键在于实现活到死的这一步吧

##### 江苏-午夜  20:46:14
> 但程序可以保持运转

##### 赤臂生  20:46:18
> 在写死的dna上是可以产生多样性和动态的

##### 赤臂生  20:46:37
> @杨柳岸 这个有办法，我已经解决了，有代码

##### 杨柳岸  20:46:46
> 那么6啊 ？

##### 江苏-午夜  20:46:51
> 死活不要过于区分

##### 赤臂生  20:47:10
> 这个涉及到另一个核心理论:循环

##### 江苏-午夜  20:47:15
> westworld区分得很鲜明，希望能看淡一点

##### 赤臂生  20:47:31
> 思维源于数据，数据源于思维

##### 杨柳岸  20:47:45
> eval apply 相互循环？

##### 江苏-午夜  20:48:05
> 一个while就可以永久工作了

##### 江苏-午夜  20:48:14
> while 1
>
##### 赤臂生  20:48:36
> 直白说吧，你的思维形成了记忆，你的记忆决定了你思考什么

##### 赤臂生  20:48:58
> 出生时，数据是空的，但这个循环会让你活

##### 赤臂生  20:49:07
> 思维是独立的维度

##### 人工智能深度学习  20:49:20
>

##### 人工智能深度学习  20:49:23
> 牛啊.

##### 赤臂生  20:49:24
> 老话，ai会认为自己活着

##### 江苏-午夜  20:49:31
> 有随机初始成分作为原料的

##### 人工智能深度学习  20:49:48
> 如果这块你都写成代码解决了的话,那关键的一环就已经有了可参考的实现了.

##### 杨柳岸  20:50:04
> 我理解这就是 eval apply 呀

##### 人工智能深度学习  20:50:11
> 可以这么理解.

##### 杨柳岸  20:50:12
> 自省

##### 赤臂生  20:50:21
> 再聊下去，会牵出另一个核心理论:相对宏微

##### 人工智能深度学习  20:50:23
> 关键是代码要怎么表达,和数据怎么交互.

##### 杨柳岸  20:50:38
> 代码就是数据啊

##### 江苏-午夜  20:50:41
> eval， apply，这不是lisp的太极么

##### 杨柳岸  20:50:44
> 数据就是代码

##### 杨柳岸  20:50:52
> 对啊对啊

##### 人工智能深度学习  20:50:52
> 是的.

##### 赤臂生  20:50:57
> @人工智能深度学习 循环代码还在改

##### 人工智能深度学习  20:51:00
> 函数式的精髓不就是这个.

##### 赤臂生  20:51:12
> @杨柳岸 对

##### 赤臂生  20:51:24
> 不再是代码运行了，而是数据

##### 杨柳岸  20:51:43
> eval('printf('hello, world')')

##### 江苏-午夜  20:51:49
> 不过循环不单单如此

##### 赤臂生  20:51:51
> 这是我去年所说的GNOP:面向动态生成式网络编程

##### 杨柳岸  20:51:53
> 数据就是代码。

##### 人工智能深度学习  20:52:33
> 恩,是的,这样的话,自编程也就顺手就解决掉了.

##### 江苏-午夜  20:52:33
> 改变数据不一定要改变代码。eval是极端了

##### 杨柳岸  20:53:00
> @人工智能深度学习 这个应该还很远

##### 赤臂生  20:53:07
> @杨柳岸 对，思维与网络循环的一个重点就是数据即思维，运行的是网络和数据

##### 杨柳岸  20:53:39
> 所以啊，还是函数式起了大作用。

##### 人工智能深度学习  20:53:42
> @杨柳岸 不远.这就是我们上次说的,使用获取数据的函数,就是

##### 杨柳岸  20:53:45
> 函数和代码其实是一个东西

##### 赤臂生  20:54:04
> @人工智能深度学习 关键在于，我这个没有性能问题，并且没有脱离现实世界的信息映射，并且非常灵活

##### 江苏-午夜  20:54:12
> 但是“被看作不同东西”

##### 人工智能深度学习  20:54:20
> 这样,就把人工编程常用的循环,条件判断什么的全部转换成函数调用,就是Lisp结构这种递归调用模式.

##### 杨柳岸  20:54:56
> 刚才群主说的循环，其实就是递归啊

##### 人工智能深度学习  20:55:12
> 肯定是递归啊.

##### 江苏-午夜  20:55:25
> @杨柳岸 你不要老往函数式上套啊

##### 赤臂生  20:55:30
> @杨柳岸 不是递归，了联想和mindValue激活思维

##### 赤臂生  20:55:36
> 了改成是

##### 杨柳岸  20:55:54
> 哦哦

##### 江苏-午夜  20:56:11
> @杨柳岸 这里强调的是，思维会改变记忆，导致下一次思维和这一次不一样了，这个循环往复的过程

##### 赤臂生  20:56:37
> @江苏-午夜 对，大家不要往程序员思维上靠，嘻嘻

##### 人工智能深度学习  20:56:38
>

##### 人工智能深度学习  20:56:54
> 天,刚才说的东西我懂了.

##### 人工智能深度学习  20:57:03
> 思维会改变记忆，导致下一次思维和这一次不一样了，这个循环往复的过程

##### 人工智能深度学习  20:57:12
> 我认为这是一个非常重要的关键点.

##### 杨柳岸  20:57:36
> 哦哦，可以理解成状态机吗

##### 赤臂生  20:57:37
> 另外循环不是转圈，是螺旋式

##### 人工智能深度学习  20:57:38
> 我凭我的直觉,我感受到了这就是智商的关键点.

##### 人工智能深度学习  20:57:47
> 不是状态机,这个不是死的.

##### 人工智能深度学习  20:58:01
> 目前机器不智能,和人类最大的差异可能就在于此.

##### 江苏-午夜  20:58:09
> " 杨柳岸 20:57:36
> 哦哦，可以理解成状态机吗 "
对。自动机

##### 杨柳岸  20:58:32
> 如果是状态机的话，就容易懂了。

##### 江苏-午夜  20:58:40
> 不过其状态，没有枚举的必要

##### 人工智能深度学习  20:58:56
> 比如机器循环的时候, 循环是死的,比如机器想100次吃饭.

##### 人工智能深度学习  20:58:59
> 结果还是吃饭.

##### 人工智能深度学习  20:59:09
> 但人类的大脑思考模式就不同.

##### 人工智能深度学习  20:59:25
> 在产生思维的时候同时也细微的改变了数据.

##### 杨柳岸  20:59:35
> 螺旋式，是什么意思呢

##### 人工智能深度学习  20:59:35
> 因为网络和数据是一体化的.

##### 人工智能深度学习  20:59:43
> 蝴蝶效应.

##### 人工智能深度学习  20:59:51
> 比如你想第一次吃,你没动.

##### 赤臂生  20:59:53
> @人工智能深度学习 你提到一个最核心的理论，就是目前系统不智能的原因

##### 人工智能深度学习  21:00:03
> 想第二次,你想到了你上次吃的火锅.

##### 赤臂生  21:00:19
> @杨柳岸 数据的宏微观是相对的

##### 人工智能深度学习  21:00:36
> 但是你想第三次的时候,你可能会注意到饭点到了,然后你去食堂去了.

##### 赤臂生  21:00:37
> 认知也是相对上升的

##### 江苏-午夜  21:00:40
> " 杨柳岸 20:59:35
> 螺旋式，是什么意思呢 "
意思是不像圆圈，走下去很快会重复

##### 人工智能深度学习  21:00:48
> 我们人类这么干感觉很正常.但这就是智能的最大体现.

##### 赤臂生  21:01:32
> @人工智能深度学习

##### 人工智能深度学习  21:01:43
> 就是人类的思维,记忆的时候,同时会不断的聚焦,也就群主说的螺旋式上升,而不是死循环.

##### 赤臂生  21:01:55
> 类比与规律，共同产生了smg的最核心理论，即“一”

##### 赤臂生  21:02:52
> @杨柳岸 试想，你学习一段话和五岁娃娃，肯定是不同的。

##### 杨柳岸  21:03:55
> 思维变化了

##### 赤臂生  21:04:25
> 这个最核心的理论有一句话:名可名，非常名。天得一以清，地得一以宁。

##### 赤臂生  21:05:04
> @杨柳岸 对，思维方式，思维方式与相对宏微理论关系密切

##### 人工智能深度学习  21:05:30
> 太厉害了.

##### 赤臂生  21:05:45
> 感觉今天和大家聊的这些，可以作为smg的介绍资料

##### 人工智能深度学习  21:05:55
> 完全可以.

##### 赤臂生  21:06:16
> 再有人不懂理论，先看今天的聊天记录，再问。

##### 人工智能深度学习  21:06:31
> 思维和数据的螺旋式上升这一点,是真正的击中了智能的要害了.

##### 人工智能深度学习  21:07:10
> 甚至可以从理论上这样去推理,就是给它足够的CPU和数据空间.

##### 人工智能深度学习  21:07:34
> 这个AI会自动象佛一样去最终领悟宇宙真理.

##### 江苏-午夜  21:07:46
> 我以前在别的群介绍自己的理论，第一句要说“人是在记忆集合上演化的自动机”

##### 赤臂生  21:07:46
> @人工智能 你想想我说的最核心那条，看是否能理解

##### 江苏-午夜  21:08:12
> 然后“演化由当前记忆唯一确定”

##### 江苏-午夜  21:08:45
> 当时把记忆当成离散的东西，现在不完全这么看了

##### 赤臂生  21:10:54
> @江苏-午夜 其实咱俩很多想法一致

##### 江苏-午夜  21:11:05
> 嗯

##### 人工智能深度学习  21:11:30
> 有这个机制,那么思维问题我认为就有解了.

##### 赤臂生  21:12:06
> @人工智能深度学习 对，还有很多，都可以解

##### 人工智能深度学习  21:12:30
> 再加上一点随机量去激活它.

##### 人工智能深度学习  21:12:46
> 从而让机器自已呆在那里不断的思考进化.

##### 人工智能深度学习  21:12:58
> 然后不断的给自已的MindValue填值.

##### 赤臂生  21:22:09
> @人工智能深度学习 对，mindValue因为关联数据有了意义，并且是特殊意义。

##### farmer  21:25:02
> 西部世界里的东西就要出现了 [摇摆]

##### farmer  21:25:16
>

##### farmer  21:25:16
>

##### 赤臂生  21:26:19
> @farmer 差远了，我只写相当于linux内核。

##### 人工智能深度学习  21:28:41
> 这10247行就是群主写的.

##### 赤臂生  21:32:12
> 电视剧那是搞笑的，一个内核很小很正常，一个完善的系统单一小块优化也不止万行。

##### 江苏-午夜  21:34:46
> 话说群主的头像出自哪？

##### 超联人工智能  21:34:55
> 电影《人工智能》

##### 江苏-午夜  21:35:11
> 哦哦，

##### 江苏-午夜  21:37:18
> 西部世界没精力追第二部了

##### 杨柳岸  22:18:50
> 这10247是代码表达的一个人

##### 杨柳岸  22:19:01
> 一个人所有的信息

##### 杨柳岸  22:19:05
> 不是主程序

##### farmer  22:19:35
> 就是主程序

##### farmer  22:19:50
> 吧

##### 杨柳岸  22:19:58
> 不是啊，是一个人的信息

##### farmer  22:20:29
>

##### farmer  22:20:36
> 这个图是第一句

##### 江苏-午夜  22:20:56
> 哦？非程序性的信息一般不用代码表示

##### 压力山大  22:23:01
> 你们这些人，太落后了。要看就看西游记。

##### 压力山大  22:23:15
>

##### 压力山大  22:24:39
> 千里眼 顺风耳  变大小 拔毛复制猴子 转换躯体变身

##### 压力山大  22:24:52
> 灵魂出窍

##### 杨柳岸  22:29:37
> @江苏-午夜 你说的自动机，是哪种类型的

##### 杨柳岸  22:31:11
> @压力山大 你说的太高深，听不懂啊

##### 江苏-午夜  22:32:27
> 不强调是什么类型的

##### 江苏-午夜  22:32:49
> 只强调是个自动机

##### 压力山大  22:34:23
> " 杨柳岸 22:31:11
> @压力山大 你说的太高深，听不懂啊 "
我开了个玩笑

##### 压力山大  22:34:59
> 他们不是在讨论看西部世界吗，我说不如看西游记

##### 江苏-午夜  22:35:37
> 没反应过来

##### 压力山大  22:35:50
> 你如果经常看欧美的科幻电影，你会发现一个趋势。

##### 压力山大  22:36:05
> 英雄们的特异功能越来越强

##### 压力山大  22:36:12
> 最后都会编程孙悟空

##### 压力山大  22:36:16
> 变成

##### 压力山大  22:37:08
> 超人 会飞
蚁人 会变大小

##### 压力山大  22:37:26
> 变形金刚 会变形

##### 杨柳岸  22:37:38
> 告他们侵权，奶奶的

##### 压力山大  22:37:39
> 雷神

##### 压力山大  22:37:59
> 美队的盾牌，

##### 压力山大  22:38:04
> 西游记里都有

##### 压力山大  22:38:29
> 凡是你能说出来的 西游记里都有

##### 压力山大  22:38:55
> 所以像西部世界这种 复制人的把戏  悟空早会了 把一根毛

##### 杨柳岸  22:39:02
> 反正我就觉得我活在虚拟世界

##### 压力山大  22:39:02
> 就变出来了

##### 压力山大  22:39:29
> 悟空还会 灵魂出窍 变化肉身=阿凡达

##### 压力山大  22:41:18
> 西游记可以说是最早 最强的 科幻

##### 压力山大  22:41:43
> 连千里耳 =电话 千里眼=电视

##### 压力山大  22:41:57
> 筋斗云 =飞机

##### 压力山大  22:42:34
> 早就预言了

##### 压力山大  22:42:55
> 连时间都预言了

##### 压力山大  22:43:09
> 天上一日 人间一年

##### 压力山大  22:43:18
> 可不是咋滴

##### 压力山大  22:43:41
> 看过 星际穿越的电影的朋友

##### 压力山大  22:44:01
> 都知道确实 时间变慢存在

##### 压力山大  22:44:43
> 欧美的影视不知道多少年，才能赶上西游记的科学脑洞

##### 压力山大  22:44:55
> 西游记里的 仙桃 仙丹

##### 压力山大  22:45:02
> 就是接下来的长生不老

##### 压力山大  22:45:16
> 基因药物

##### 压力山大  22:51:54
> " 杨柳岸 22:39:02
> 反正我就觉得我活在虚拟世界 "

西游记里 也说了 天有九重

##### 杨柳岸  23:50:43
> 看了介绍的视频

##### 杨柳岸  23:50:58
> 差不多能懂表面的意思

##### 杨柳岸  23:51:00
>

##### 杨柳岸  23:51:51
> 我理解，这个mindvalue 是一个数据结构

##### 杨柳岸  23:51:56
> 有类型

##### 杨柳岸  23:52:08
> 有值

##### 杨柳岸  23:52:36
> 只是这些数据，都是最微小的粒子

##### 杨柳岸  23:52:50
> 类似计算机的01
>
##### 杨柳岸  23:53:27
> 比如，所有汉字的集合，所有英语字母的集合，所有像素点的集合

##### 杨柳岸  23:53:42
> 这些是微观数据

##### 杨柳岸  23:53:51
> 这思路很赞

##### 杨柳岸  23:55:46
> 微观数据是基础抽象

##### 杨柳岸  23:56:17
> 在微观之上，如何抽象宏观的数据，感觉群主没讲太明白呀

##### 杨柳岸  23:57:11
> 通过训练，如何让让mindvalue产生变化，这个也是需要学习的吧

##### 杨柳岸  23:58:05
> 还是说，我们会给它默认的行为

##### Big Big Risk  00:17:40
> 宝宝玩扔皮球，扔两下看见皮球会弹起，很开心，是什么让他只需要扔几下就捕捉到皮球弹起这个最强的信号呢（至少人类是认为这个信号是最强的）

##### Big Big Risk  00:19:12
> 深度训练都是要成千上万数据才捕捉到信号啊

##### 赤臂生  06:35:40
> @杨柳岸 你可以看看网络构建的全过程

##### 赤臂生  06:35:48
> 然后就明白了

##### 赤臂生  06:36:31
> 昨天晚上我们少聊了一个最核心的理论，就是“一”

##### 赤臂生  06:36:44
> 即定义，意义，概念

##### 赤臂生  06:37:48
> 网络中每个节点都是宏信息，而每个节点的意义来自与其关联的节点。

##### 赤臂生  06:38:23
> 我在描述的是“定义”的生成过程

##### 赤臂生  06:39:22
> 不止是结果，并且“定义”是从模糊到相对确切的过程，没有绝对确切的定义。

##### 赤臂生  06:39:49
> “一”是smg中最核心的理论，即从无到有。

##### 赤臂生  06:41:17
> 你如果能理解了这其中的动态，模糊，及整个网络最初的构建过程，就明白我的意思了。而这些视频中应该都有提到，也可以结合代码和笔记里的示图了解。

##### 赤臂生  06:57:29
> 我给你发个前天的聊天截图，有谈到构建流程。

##### 赤臂生  06:58:24
>
